{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание по программированию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Производные. Частные производные. Градиент. Градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам понадобится библиотека **numpy** - о ней было рассказано на первой лекции. Если ничего не помните, то можно обратиться к следующим ресурсам:\n",
    "1. http://pyviy.blogspot.com/2009/09/numpy.html\n",
    "2. https://pythonworld.ru/numpy (Часть 1, Часть 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно напишем функцию, которая считает расстояние между двумя точками в произвольном пространстве. Математически это выглядит так $$dist(x, y) = \\sum_{i=1}^{n}(x_{i} - y_{i})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x, y):\n",
    "    # Здесь мы можем обойтись без явного суммирования\n",
    "    # Если y и x - вектора из R^{n}, тогда \n",
    "    # y^{2} - x^{2} - тоже вектор из R^{n}\n",
    "    # (здесь x^{2}, y^{2} означает возведение в квадрат каждой из компонент вектора)\n",
    "    # Используя np.sum с атрибутом axis = 0 получим суммирование по столбцу\n",
    "    return np.sqrt(abs(np.sum(y ** 2 - x ** 2, axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно пишут не универсальную функцию, которая принимает на вход функцию, минимум которой надо найти, и ее градиент, а явно задают эту функции внутри. Например, напишем функцию, которая будет находить точку минимума для функции многих переменных $$F(x, y) = x^{2} + y^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(starting_point,\n",
    "                     learning_rate = None, iter_max = None,\n",
    "                     precision = None, verbose = None, output = None):\n",
    "    f = lambda x: x[0] ** 2 + x[1] ** 2 # Обычная функция многих переменнных\n",
    "                                        # F(x, y) = x^2 + y^2\n",
    "    df_x = lambda x: 2 * x     # Частная производная функции F по первой переменной\n",
    "    df_y = lambda y: 2 * y     # Частная производная функции F по второй переменной\n",
    "\n",
    "    # Инициализация опциональных параметров\n",
    "    iter_num = 0\n",
    "    if learning_rate is None:\n",
    "        learning_rate = 0.001\n",
    "    if iter_max is None:\n",
    "        iter_max = 1e7\n",
    "    if precision is None:\n",
    "        precision = 1e-7\n",
    "    if verbose is None:\n",
    "        verbose = False\n",
    "    if output is None:\n",
    "        output = False\n",
    "\n",
    "    # Градиентный спуск\n",
    "    point = np.array([starting_point[0] - learning_rate * df_x(starting_point[0]),\n",
    "                      starting_point[1] - learning_rate * df_y(starting_point[1])])\n",
    "\n",
    "    while dist(point, starting_point) > 1e-7 and iter_num < iter_max:\n",
    "        ++iter_num\n",
    "        starting_point, point = np.array([\n",
    "            starting_point[0] - learning_rate * df_x(starting_point[0]),\n",
    "            starting_point[1] - learning_rate * df_y(starting_point[1])]),\\\n",
    "            starting_point\n",
    "        if verbose:\n",
    "            print(starting_point, point)\n",
    "\n",
    "    if output:\n",
    "        return point, f(point)\n",
    "    else:\n",
    "        return np.round(point, 3), np.round(f(point), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0., -0.]), 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(np.array([2, -5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам необходимо написать функцию, которая будет находить минимум функции многих переменных $$F(x, y, z, t) = x^{4}y^{2} + z^{2}t^{2}$$\n",
    "Указание - вам надо *немного* модифицировать предыдущую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(starting_point,\n",
    "                     learning_rate = None, iter_max = None,\n",
    "                     precision = None, verbose = None, output = None):\n",
    "    f = lambda x: x[0] ** 4 * x[1] ** 2  + x[2] ** 2 * x[3] ** 2\n",
    "    df_x = lambda x: 4 * x[0] ** 3 * x[1] ** 2\n",
    "    df_y = lambda x: 2 * x[0] ** 4 * x[1]\n",
    "    df_z = lambda x: 2 * x[0] * x[1] ** 2\n",
    "    df_t = lambda x: 2 * x[0] ** 2 * x[1]\n",
    "\n",
    "    # Инициализация опциональных параметров\n",
    "    iter_num = 0\n",
    "    if learning_rate is None:\n",
    "        learning_rate = 0.001\n",
    "    if iter_max is None:\n",
    "        iter_max = 1e7\n",
    "    if precision is None:\n",
    "        precision = 1e-7\n",
    "    if verbose is None:\n",
    "        verbose = False\n",
    "    if output is None:\n",
    "        output = False\n",
    "\n",
    "    # Градиентный спуск\n",
    "    point = np.array([\n",
    "        starting_point[0] - learning_rate * df_x((starting_point[0], starting_point[1])),\n",
    "        starting_point[1] - learning_rate * df_y((starting_point[0], starting_point[1])),\n",
    "        starting_point[2] - learning_rate * df_z((starting_point[2], starting_point[3])),\n",
    "        starting_point[3] - learning_rate * df_t((starting_point[2], starting_point[3]))])\n",
    "\n",
    "    while dist(point, starting_point) > 1e-7 and iter_num < iter_max:\n",
    "        iter_num += 1\n",
    "        starting_point, point = np.array([\n",
    "            starting_point[0] - learning_rate * df_x((starting_point[0], starting_point[1])),\n",
    "            starting_point[1] - learning_rate * df_y((starting_point[0], starting_point[1])),\n",
    "            starting_point[2] - learning_rate * df_z((starting_point[2], starting_point[3])),\n",
    "            starting_point[3] - learning_rate * df_t((starting_point[2], starting_point[3]))]),\\\n",
    "            starting_point\n",
    "        if verbose:\n",
    "            print(starting_point, point)\n",
    "\n",
    "    if output:\n",
    "        return point, f(point)\n",
    "    else:\n",
    "        return np.round(point, 3), np.round(f(point), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.052, -0.677,  0.05 ,  0.05 ]), 0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(np.array([1, -1, 1, 1]),\n",
    "                 learning_rate=0.1, iter_max=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
